{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1 Get Started on spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2 Linguistic Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process text/corpus with nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Dostoevsky was the son of a doctor. \n",
    "His parents were very hard-working and deeply religious people,\n",
    "but so poor that they lived with their five children in only\n",
    "two rooms. The father and mother spent their evenings\n",
    "in reading aloud to their children, generally from books of\n",
    "a serious character.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get text from file\n",
    "\n",
    "text = open('sample.txt').read()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Tokenization\n",
    "\n",
    "doc = nlp(u'Today is a great day')\n",
    "[word.text for word in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = open('sample.txt').read()\n",
    "# doc = nlp(text)\n",
    "\n",
    "word_tokens = [token.text for token in doc]\n",
    "word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence Tokenization\n",
    "\n",
    "doc = nlp(u\"This is a sentence. This is another sentence.\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = open('sample.txt').read()\n",
    "doc = nlp(text)\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc[1].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[word.is_stop for word in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab[\"the\"].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[word.is_stop for word in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = nlp(u'running run')\n",
    "doc = nlp(u'meaning mean')\n",
    "doc = nlp(u'meanness meaning mean')\n",
    "\n",
    "for token in doc:\n",
    "\tprint(token.text,token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Apples and oranges are similar. Boots and hippos aren't.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = open('sample.txt').read()\n",
    "# doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token, token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Speech (POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DET\n",
      "cat NOUN\n",
      "sit VERB\n",
      "on ADP\n",
      "the DET\n",
      "mat NOUN\n"
     ]
    }
   ],
   "source": [
    "# text = open('sample.txt').read()\n",
    "# doc = nlp(text)\n",
    "\n",
    "doc = nlp(u'The cat sit on the mat')\n",
    "for token in doc:\n",
    "    print(token.text,token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DT\n",
      "cat NN\n",
      "sit VBP\n",
      "on IN\n",
      "the DT\n",
      "mat NN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for token in doc:\n",
    "    print(token.text,token.tag_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun Chuck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat cat nsubj sit\n",
      "the mat mat pobj on\n"
     ]
    }
   ],
   "source": [
    "# text = open('sample.txt').read()\n",
    "# doc = nlp(text)\n",
    "\n",
    "doc = nlp(u'The cat sit on the mat')\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, chunk.root.text, chunk.root.dep_, chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous cars cars nsubj shift\n",
      "insurance liability liability dobj shift\n",
      "manufacturers manufacturers pobj toward\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u\"Autonomous cars shift insurance liability toward manufacturers\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, chunk.root.text, chunk.root.dep_,\n",
    "          chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Visualize Dependency and POS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc = nlp(u'The cat sit on the mat')\n",
    "displacy.serve(doc, style='dep',displacy.serve(doc, style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc = nlp(u'The cat sit on the mat')\n",
    "options = {'compact': True, 'bg': '#09a3d5',\n",
    "           'color': 'white', 'font': 'Source Sans Pro'}\n",
    "displacy.serve(doc, style='dep', options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc = nlp(u'The cat sit on the mat')\n",
    "html = displacy.render([doc], style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Lee Kuan Yew is the prime minister for Singapore')\n",
    "\n",
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc = nlp(u'Lee Kuan Yew is the prime minister for Singapore')\n",
    "\n",
    "doc.user_data['title'] = 'This is a title'\n",
    "displacy.serve(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc = nlp(u'Lee Kuan Yew is the prime minister for Singapore')\n",
    "\n",
    "colors = {'ORG': 'linear-gradient(90deg, #aa9cfc, #fc9ce7)'}\n",
    "options = {'ents': ['ORG'], 'colors': colors}\n",
    "displacy.serve(doc, style='ent', options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc = nlp(u'Lee Kuan Yew is the prime minister for Singapore')\n",
    "\n",
    "html = displacy.render([doc], style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc = nlp(u'Lee Kuan Yew is the prime minister for Singapore')\n",
    "\n",
    "colors = {'ORG': 'linear-gradient(90deg, #aa9cfc, #fc9ce7)'}\n",
    "options = {'ents': ['ORG'], 'colors': colors}\n",
    "html = displacy.render([doc], style='ent', jupyter=True,options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 Processing Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disable Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['parser', 'tagger'])\n",
    "doc = nlp(u'The cat sit on the mat')\n",
    "for token in doc:\n",
    "    print(token.text,token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "doc = nlp(u'The cat sit on the mat')\n",
    "for token in doc:\n",
    "    print(token.text,token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "nlp.remove_pipe('tagger')\n",
    "doc = nlp(u'The cat sit on the mat')\n",
    "for token in doc:\n",
    "    print(token.text,token.pos_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "nlp.rename_pipe('ner', 'entityrecognizer')\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Custom Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_component(doc):\n",
    "    print(\"After tokenization, this doc has %s tokens.\" % len(doc))\n",
    "    if len(doc) < 10:\n",
    "        print(\"This is a pretty short document.\")\n",
    "    return doc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "nlp.add_pipe(my_component, name='print_info', first=True)\n",
    "nlp.pipe_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'The cat sit on the mat')\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4 Vectors & Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "embedding = Word2Vec(gutenberg.sents(),min_count=1, window=5, size=32)\n",
    "\n",
    "print(embedding.most_similar('man', topn=5))\n",
    "print(embedding.most_similar('woman', topn=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog dog 1.0\n",
      "dog cat 0.80168533\n",
      "dog banana 0.24327648\n",
      "dog afskfsd 0.0\n",
      "cat dog 0.80168533\n",
      "cat cat 1.0\n",
      "cat banana 0.28154367\n",
      "cat afskfsd 0.0\n",
      "banana dog 0.24327646\n",
      "banana cat 0.2815437\n",
      "banana banana 1.0\n",
      "banana afskfsd 0.0\n",
      "afskfsd dog 0.0\n",
      "afskfsd cat 0.0\n",
      "afskfsd banana 0.0\n",
      "afskfsd afskfsd 1.0\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "tokens = nlp(u'dog cat banana afskfsd')\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.15067  , -0.024468 , -0.23368  , -0.23378  , -0.18382  ,\n",
       "        0.32711  , -0.22084  , -0.28777  ,  0.12759  ,  1.1656   ,\n",
       "       -0.64163  , -0.098455 , -0.62397  ,  0.010431 , -0.25653  ,\n",
       "        0.31799  ,  0.037779 ,  1.1904   , -0.17714  , -0.2595   ,\n",
       "       -0.31461  ,  0.038825 , -0.15713  , -0.13484  ,  0.36936  ,\n",
       "       -0.30562  , -0.40619  , -0.38965  ,  0.3686   ,  0.013963 ,\n",
       "       -0.6895   ,  0.004066 , -0.1367   ,  0.32564  ,  0.24688  ,\n",
       "       -0.14011  ,  0.53889  , -0.80441  , -0.1777   , -0.12922  ,\n",
       "        0.16303  ,  0.14917  , -0.068429 , -0.33922  ,  0.18495  ,\n",
       "       -0.082544 , -0.46892  ,  0.39581  , -0.13742  , -0.35132  ,\n",
       "        0.22223  , -0.144    , -0.048287 ,  0.3379   , -0.31916  ,\n",
       "        0.20526  ,  0.098624 , -0.23877  ,  0.045338 ,  0.43941  ,\n",
       "        0.030385 , -0.013821 , -0.093273 , -0.18178  ,  0.19438  ,\n",
       "       -0.3782   ,  0.70144  ,  0.16236  ,  0.0059111,  0.024898 ,\n",
       "       -0.13613  , -0.11425  , -0.31598  , -0.14209  ,  0.028194 ,\n",
       "        0.5419   , -0.42413  , -0.599    ,  0.24976  , -0.27003  ,\n",
       "        0.14964  ,  0.29287  , -0.31281  ,  0.16543  , -0.21045  ,\n",
       "       -0.4408   ,  1.2174   ,  0.51236  ,  0.56209  ,  0.14131  ,\n",
       "        0.092514 ,  0.71396  , -0.021051 , -0.33704  , -0.20275  ,\n",
       "       -0.36181  ,  0.22055  , -0.25665  ,  0.28425  , -0.16968  ,\n",
       "        0.058029 ,  0.61182  ,  0.31576  , -0.079185 ,  0.35538  ,\n",
       "       -0.51236  ,  0.4235   , -0.30033  , -0.22376  ,  0.15223  ,\n",
       "       -0.048292 ,  0.23532  ,  0.46507  , -0.67579  , -0.32905  ,\n",
       "        0.08446  , -0.22123  , -0.045333 ,  0.34463  , -0.1455   ,\n",
       "       -0.18047  , -0.17887  ,  0.96879  , -1.0028   , -0.47343  ,\n",
       "        0.28542  ,  0.56382  , -0.33211  , -0.38275  , -0.2749   ,\n",
       "       -0.22955  , -0.24265  , -0.37689  ,  0.24822  ,  0.36941  ,\n",
       "        0.14651  , -0.37864  ,  0.31134  , -0.28449  ,  0.36948  ,\n",
       "       -2.8174   , -0.38319  , -0.022373 ,  0.56376  ,  0.40131  ,\n",
       "       -0.42131  , -0.11311  , -0.17317  ,  0.1411   , -0.13194  ,\n",
       "        0.18494  ,  0.097692 , -0.097341 , -0.23987  ,  0.16631  ,\n",
       "       -0.28556  ,  0.0038654,  0.53292  , -0.32367  , -0.38744  ,\n",
       "        0.27011  , -0.34181  , -0.27702  , -0.67279  , -0.10771  ,\n",
       "       -0.062189 , -0.24783  , -0.070884 , -0.20898  ,  0.062404 ,\n",
       "        0.022372 ,  0.13408  ,  0.1305   , -0.19546  , -0.46849  ,\n",
       "        0.77731  , -0.043978 ,  0.3827   , -0.23376  ,  1.0457   ,\n",
       "       -0.14371  , -0.3565   , -0.080713 , -0.31047  , -0.57822  ,\n",
       "       -0.28067  , -0.069678 ,  0.068929 , -0.16227  , -0.63934  ,\n",
       "       -0.62149  ,  0.11222  , -0.16969  , -0.54637  ,  0.49661  ,\n",
       "        0.46565  ,  0.088294 , -0.48496  ,  0.69263  , -0.068977 ,\n",
       "       -0.53709  ,  0.20802  , -0.42987  , -0.11921  ,  0.1174   ,\n",
       "       -0.18443  ,  0.43797  , -0.1236   ,  0.3607   , -0.19608  ,\n",
       "       -0.35366  ,  0.18808  , -0.5061   ,  0.14455  , -0.024368 ,\n",
       "       -0.10772  , -0.0115   ,  0.58634  , -0.054461 ,  0.0076487,\n",
       "       -0.056297 ,  0.27193  ,  0.23096  , -0.29296  , -0.24325  ,\n",
       "        0.10317  , -0.10014  ,  0.7089   ,  0.17402  , -0.0037509,\n",
       "       -0.46304  ,  0.11806  , -0.16457  , -0.38609  ,  0.14524  ,\n",
       "        0.098122 , -0.12352  , -0.1047   ,  0.39047  , -0.3063   ,\n",
       "       -0.65375  , -0.0044248, -0.033876 ,  0.037114 , -0.27472  ,\n",
       "        0.0053147,  0.30737  ,  0.12528  , -0.19527  , -0.16461  ,\n",
       "        0.087518 , -0.051107 , -0.16323  ,  0.521    ,  0.10822  ,\n",
       "       -0.060379 , -0.71735  , -0.064327 ,  0.37043  , -0.41054  ,\n",
       "       -0.2728   , -0.30217  ,  0.015771 , -0.43056  ,  0.35647  ,\n",
       "        0.17188  , -0.54598  , -0.21541  , -0.044889 , -0.10597  ,\n",
       "       -0.54391  ,  0.53908  ,  0.070938 ,  0.097839 ,  0.097908 ,\n",
       "        0.17805  ,  0.18995  ,  0.49962  , -0.18529  ,  0.051234 ,\n",
       "        0.019574 ,  0.24805  ,  0.3144   , -0.29304  ,  0.54235  ,\n",
       "        0.46672  ,  0.26017  , -0.44705  ,  0.28287  , -0.033345 ,\n",
       "       -0.33181  , -0.10902  , -0.023324 ,  0.2106   , -0.29633  ,\n",
       "        0.81506  ,  0.038524 ,  0.46004  ,  0.17187  , -0.29804  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "tokens = nlp(u'dog cat banana afskfsd')\n",
    "tokens[1].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in tokens:\n",
    "    print(token.text, token.vector_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5 Machine Learning using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-0e58a46824a7>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-0e58a46824a7>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    df  ==  pdpd..read_csvread_csv('research_paper.csv')\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "dfdf  ==  pdpd..read_csvread_csv('research_paper.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
